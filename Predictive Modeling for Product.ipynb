{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f4437b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6812a162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-3.0.2-py3-none-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\priya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from xgboost) (2.3.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\priya\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from xgboost) (1.15.3)\n",
      "Downloading xgboost-3.0.2-py3-none-win_amd64.whl (150.0 MB)\n",
      "   ---------------------------------------- 0.0/150.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.8/150.0 MB 12.7 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 5.2/150.0 MB 14.9 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 9.4/150.0 MB 16.4 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 13.1/150.0 MB 16.8 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 16.8/150.0 MB 17.5 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 21.0/150.0 MB 17.5 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 24.4/150.0 MB 17.2 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 28.6/150.0 MB 17.6 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 32.5/150.0 MB 17.8 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 36.7/150.0 MB 18.1 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 41.2/150.0 MB 18.3 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 45.4/150.0 MB 18.3 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 49.0/150.0 MB 18.4 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 53.2/150.0 MB 18.4 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 57.1/150.0 MB 18.4 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 61.3/150.0 MB 18.5 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 65.8/150.0 MB 18.6 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 69.7/150.0 MB 18.7 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 71.6/150.0 MB 18.6 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 75.0/150.0 MB 18.0 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 79.2/150.0 MB 18.1 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 83.1/150.0 MB 18.2 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 87.6/150.0 MB 18.3 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 92.0/150.0 MB 18.3 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 95.7/150.0 MB 18.3 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 99.9/150.0 MB 18.4 MB/s eta 0:00:03\n",
      "   --------------------------- ----------- 104.1/150.0 MB 18.5 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 108.3/150.0 MB 18.5 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 112.2/150.0 MB 18.5 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 116.4/150.0 MB 18.5 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 120.6/150.0 MB 18.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 125.0/150.0 MB 18.6 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 129.5/150.0 MB 18.6 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 133.4/150.0 MB 18.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 137.4/150.0 MB 18.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 141.6/150.0 MB 18.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 145.5/150.0 MB 18.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  149.9/150.0 MB 18.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  149.9/150.0 MB 18.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  149.9/150.0 MB 18.8 MB/s eta 0:00:01\n",
      "   --------------------------------------- 150.0/150.0 MB 17.4 MB/s eta 0:00:00\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-3.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f08b08cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76036585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Year_Birth', 'Education', 'Marital_Status', 'Income', 'Kidhome',\n",
      "       'Teenhome', 'Dt_Customer', 'Recency', 'MntWines', 'MntFruits',\n",
      "       'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts',\n",
      "       'MntGoldProds', 'NumDealsPurchases', 'NumWebPurchases',\n",
      "       'NumCatalogPurchases', 'NumStorePurchases', 'NumWebVisitsMonth',\n",
      "       'AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5', 'AcceptedCmp1',\n",
      "       'AcceptedCmp2', 'Complain', 'Z_CostContact', 'Z_Revenue', 'Response'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b7575c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column with the name of the top product category\n",
    "product_cols = ['MntWines', 'MntFruits', 'MntMeatProducts',\n",
    "                'MntFishProducts', 'MntSweetProducts', 'MntGoldProds']\n",
    "\n",
    "df[\"Top_Product\"] = df[product_cols].idxmax(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0b7bec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"Top_Product\"]\n",
    "X = df.drop(product_cols + [\"Top_Product\", \"Dt_Customer\"], axis=1)\n",
    "X = pd.get_dummies(X, drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78545d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year_Birth              0\n",
      "Education               0\n",
      "Marital_Status          0\n",
      "Income                 24\n",
      "Kidhome                 0\n",
      "Teenhome                0\n",
      "Dt_Customer             0\n",
      "Recency                 0\n",
      "MntWines                0\n",
      "MntFruits               0\n",
      "MntMeatProducts         0\n",
      "MntFishProducts         0\n",
      "MntSweetProducts        0\n",
      "MntGoldProds            0\n",
      "NumDealsPurchases       0\n",
      "NumWebPurchases         0\n",
      "NumCatalogPurchases     0\n",
      "NumStorePurchases       0\n",
      "NumWebVisitsMonth       0\n",
      "AcceptedCmp3            0\n",
      "AcceptedCmp4            0\n",
      "AcceptedCmp5            0\n",
      "AcceptedCmp1            0\n",
      "AcceptedCmp2            0\n",
      "Complain                0\n",
      "Z_CostContact           0\n",
      "Z_Revenue               0\n",
      "Response                0\n",
      "Top_Product             0\n",
      "dtype: int64\n",
      "Rows with NaN: 24\n"
     ]
    }
   ],
   "source": [
    "# Check how many NaNs exist now\n",
    "print(df.isna().sum())\n",
    "\n",
    "# Or just total rows with any NaN\n",
    "print(\"Rows with NaN:\", df.isna().any(axis=1).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e0d104d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09ea6e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set target and features\n",
    "y = df_clean[\"Top_Product\"]\n",
    "X = df_clean.drop(product_cols + [\"Top_Product\", \"Dt_Customer\"], axis=1)\n",
    "\n",
    "# Encode categoricals\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37ea8d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode y labels numerically for XGBoost (e.g., MntWines → 0, etc.)\n",
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train)\n",
    "y_test_enc = le.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "323ea09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Logistic Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 300 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=300).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training k-NN...\n",
      "\n",
      "Training Decision Tree...\n",
      "\n",
      "Training Random Forest...\n",
      "\n",
      "Training XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [15:16:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    # Train with encoded labels ONLY for XGBoost\n",
    "    if name == \"XGBoost\":\n",
    "        model.fit(X_train, y_train_enc)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_labels = le.inverse_transform(y_pred)  # Convert back to string labels\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_labels = y_pred\n",
    "\n",
    "    # Evaluation\n",
    "    acc = accuracy_score(y_test, y_pred_labels)\n",
    "    prec = precision_score(y_test, y_pred_labels, average='macro', zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred_labels, average='macro', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred_labels, average='macro', zero_division=0)\n",
    "\n",
    "    # Probabilities + AUC-ROC\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_proba = model.predict_proba(X_test)\n",
    "        y_test_bin = LabelBinarizer().fit_transform(y_test)\n",
    "        auc = roc_auc_score(y_test_bin, y_proba, average='macro', multi_class='ovr')\n",
    "    else:\n",
    "        auc = \"N/A\"\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": round(acc, 4),\n",
    "        \"Precision\": round(prec, 4),\n",
    "        \"Recall\": round(rec, 4),\n",
    "        \"F1-Score\": round(f1, 4),\n",
    "        \"AUC-ROC (Macro)\": round(auc, 4) if auc != \"N/A\" else \"N/A\"\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6094a5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results).set_index(\"Model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12391844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Accuracy  Precision  Recall  F1-Score  AUC-ROC (Macro)\n",
      "Model                                                                      \n",
      "Logistic Regression    0.7365     0.2010  0.2207    0.2065           0.7828\n",
      "k-NN                   0.6959     0.4618  0.3824    0.4009           0.7299\n",
      "Decision Tree          0.7095     0.3747  0.4168    0.3842           0.6586\n",
      "Random Forest          0.7883     0.5106  0.4132    0.4437           0.8855\n",
      "Logistic Regression    0.7365     0.2010  0.2207    0.2065           0.7828\n",
      "k-NN                   0.6959     0.4618  0.3824    0.4009           0.7299\n",
      "Decision Tree          0.7095     0.3747  0.4168    0.3842           0.6586\n",
      "Random Forest          0.7883     0.5106  0.4132    0.4437           0.8855\n",
      "XGBoost                0.7725     0.5331  0.4313    0.4666           0.8896\n"
     ]
    }
   ],
   "source": [
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c4f35a",
   "metadata": {},
   "source": [
    "### HyperParameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "faeef237",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode string labels into integers (needed for XGBoost)\n",
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train)\n",
    "y_test_enc = le.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90eb7454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Tuning Logistic Regression...\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1264: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 300 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=300).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best Params: {'C': 0.1, 'max_iter': 300, 'solver': 'lbfgs'}\n",
      "\n",
      "🔍 Tuning k-NN...\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "✅ Best Params: {'metric': 'manhattan', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "\n",
      "🔍 Tuning Decision Tree...\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "✅ Best Params: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "\n",
      "🔍 Tuning Random Forest...\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "✅ Best Params: {'bootstrap': True, 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "\n",
      "🔍 Tuning XGBoost...\n",
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [15:23:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best Params: {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 200, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    print(f\"\\n🔍 Tuning {name}...\")\n",
    "    grid = GridSearchCV(model, param_grids[name], cv=3, scoring='f1_macro', n_jobs=-1, verbose=1)\n",
    "    \n",
    "    if name == \"XGBoost\":\n",
    "        grid.fit(X_train, y_train_enc)\n",
    "        best_models[name] = grid.best_estimator_\n",
    "    else:\n",
    "        grid.fit(X_train, y_train)\n",
    "        best_models[name] = grid.best_estimator_\n",
    "    \n",
    "    print(\"✅ Best Params:\", grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "710bf76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Final Evaluation of Tuned Models:\n",
      "\n",
      "📌 Logistic Regression\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      " MntFishProducts       0.00      0.00      0.00        12\n",
      "       MntFruits       0.00      0.00      0.00         2\n",
      "    MntGoldProds       0.41      0.30      0.35        30\n",
      " MntMeatProducts       0.00      0.00      0.00        77\n",
      "MntSweetProducts       0.00      0.00      0.00         3\n",
      "        MntWines       0.75      0.99      0.85       320\n",
      "\n",
      "        accuracy                           0.73       444\n",
      "       macro avg       0.19      0.22      0.20       444\n",
      "    weighted avg       0.57      0.73      0.64       444\n",
      "\n",
      "🔹 AUC-ROC (Macro): 0.7929455985598715\n",
      "------------------------------------------------------------\n",
      "\n",
      "📌 k-NN\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      " MntFishProducts       0.20      0.08      0.12        12\n",
      "       MntFruits       0.50      0.50      0.50         2\n",
      "    MntGoldProds       0.32      0.40      0.36        30\n",
      " MntMeatProducts       0.37      0.32      0.34        77\n",
      "MntSweetProducts       0.00      0.00      0.00         3\n",
      "        MntWines       0.82      0.85      0.83       320\n",
      "\n",
      "        accuracy                           0.70       444\n",
      "       macro avg       0.37      0.36      0.36       444\n",
      "    weighted avg       0.68      0.70      0.69       444\n",
      "\n",
      "🔹 AUC-ROC (Macro): 0.753500055626029\n",
      "------------------------------------------------------------\n",
      "\n",
      "📌 Decision Tree\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      " MntFishProducts       0.33      0.33      0.33        12\n",
      "       MntFruits       0.20      0.50      0.29         2\n",
      "    MntGoldProds       0.48      0.43      0.46        30\n",
      " MntMeatProducts       0.36      0.42      0.38        77\n",
      "MntSweetProducts       0.00      0.00      0.00         3\n",
      "        MntWines       0.85      0.82      0.83       320\n",
      "\n",
      "        accuracy                           0.70       444\n",
      "       macro avg       0.37      0.42      0.38       444\n",
      "    weighted avg       0.71      0.70      0.71       444\n",
      "\n",
      "🔹 AUC-ROC (Macro): 0.6578236906997901\n",
      "------------------------------------------------------------\n",
      "\n",
      "📌 Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      " MntFishProducts       0.17      0.08      0.11        12\n",
      "       MntFruits       1.00      0.50      0.67         2\n",
      "    MntGoldProds       0.43      0.50      0.46        30\n",
      " MntMeatProducts       0.60      0.47      0.53        77\n",
      "MntSweetProducts       0.00      0.00      0.00         3\n",
      "        MntWines       0.87      0.93      0.90       320\n",
      "\n",
      "        accuracy                           0.79       444\n",
      "       macro avg       0.51      0.41      0.44       444\n",
      "    weighted avg       0.77      0.79      0.78       444\n",
      "\n",
      "🔹 AUC-ROC (Macro): 0.8854542325209951\n",
      "------------------------------------------------------------\n",
      "\n",
      "📌 XGBoost\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      " MntFishProducts       0.29      0.17      0.21        12\n",
      "       MntFruits       1.00      0.50      0.67         2\n",
      "    MntGoldProds       0.52      0.57      0.54        30\n",
      " MntMeatProducts       0.55      0.48      0.51        77\n",
      "MntSweetProducts       0.00      0.00      0.00         3\n",
      "        MntWines       0.87      0.92      0.89       320\n",
      "\n",
      "        accuracy                           0.79       444\n",
      "       macro avg       0.54      0.44      0.47       444\n",
      "    weighted avg       0.77      0.79      0.78       444\n",
      "\n",
      "🔹 AUC-ROC (Macro): N/A\n",
      "------------------------------------------------------------\n",
      "\n",
      "✅ Summary Table After Hyperparameter Tuning:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>AUC-ROC (Macro)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.7342</td>\n",
       "      <td>0.1934</td>\n",
       "      <td>0.2151</td>\n",
       "      <td>0.2001</td>\n",
       "      <td>0.7929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k-NN</th>\n",
       "      <td>0.6982</td>\n",
       "      <td>0.3685</td>\n",
       "      <td>0.3591</td>\n",
       "      <td>0.3589</td>\n",
       "      <td>0.7535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.7027</td>\n",
       "      <td>0.3693</td>\n",
       "      <td>0.4168</td>\n",
       "      <td>0.3817</td>\n",
       "      <td>0.6578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.7883</td>\n",
       "      <td>0.5106</td>\n",
       "      <td>0.4132</td>\n",
       "      <td>0.4437</td>\n",
       "      <td>0.8855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.7883</td>\n",
       "      <td>0.5375</td>\n",
       "      <td>0.4382</td>\n",
       "      <td>0.4707</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Accuracy  Precision  Recall  F1-Score AUC-ROC (Macro)\n",
       "Model                                                                     \n",
       "Logistic Regression    0.7342     0.1934  0.2151    0.2001          0.7929\n",
       "k-NN                   0.6982     0.3685  0.3591    0.3589          0.7535\n",
       "Decision Tree          0.7027     0.3693  0.4168    0.3817          0.6578\n",
       "Random Forest          0.7883     0.5106  0.4132    0.4437          0.8855\n",
       "XGBoost                0.7883     0.5375  0.4382    0.4707             N/A"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Store results\n",
    "final_results = []\n",
    "\n",
    "print(\"\\n🔍 Final Evaluation of Tuned Models:\\n\")\n",
    "\n",
    "for name, model in best_models.items():\n",
    "    print(f\"📌 {name}\")\n",
    "    \n",
    "    # Use encoded labels only for XGBoost\n",
    "    if name == \"XGBoost\":\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_true = y_test_enc\n",
    "        proba = model.predict_proba(X_test)\n",
    "    else:\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_true = y_test\n",
    "        proba = model.predict_proba(X_test) if hasattr(model, \"predict_proba\") else None\n",
    "\n",
    "    # Print classification report\n",
    "    print(classification_report(y_true, y_pred, target_names=le.classes_))\n",
    "\n",
    "    # Calculate macro AUC-ROC\n",
    "    try:\n",
    "        auc_macro = roc_auc_score(le.transform(y_true), proba, multi_class='ovr', average='macro')\n",
    "    except:\n",
    "        auc_macro = \"N/A\"\n",
    "\n",
    "    # Append to final results\n",
    "    final_results.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": round(accuracy_score(y_true, y_pred), 4),\n",
    "        \"Precision\": round(precision_score(y_true, y_pred, average='macro', zero_division=0), 4),\n",
    "        \"Recall\": round(recall_score(y_true, y_pred, average='macro', zero_division=0), 4),\n",
    "        \"F1-Score\": round(f1_score(y_true, y_pred, average='macro', zero_division=0), 4),\n",
    "        \"AUC-ROC (Macro)\": round(auc_macro, 4) if auc_macro != \"N/A\" else \"N/A\"\n",
    "    })\n",
    "    \n",
    "    print(f\"🔹 AUC-ROC (Macro): {auc_macro}\\n\" + \"-\"*60 + \"\\n\")\n",
    "\n",
    "# Show final performance table\n",
    "results_df_tuned = pd.DataFrame(final_results).set_index(\"Model\")\n",
    "print(\"✅ Summary Table After Hyperparameter Tuning:\")\n",
    "display(results_df_tuned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ccbcfba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff2b04f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "ensemble = VotingClassifier(estimators=[\n",
    "    ('rf', best_models['Random Forest']),\n",
    "    ('xgb', best_models['XGBoost'])\n",
    "], voting='soft')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "77b25706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: No matching distribution found for tensorflow\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "75136ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: No matching distribution found for tensorflow\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow keras scikit-learn pandas matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a815a0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Year_Birth', 'Education', 'Marital_Status', 'Income', 'Kidhome', 'Teenhome', 'Dt_Customer', 'Recency', 'MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', 'MntGoldProds', 'NumDealsPurchases', 'NumWebPurchases', 'NumCatalogPurchases', 'NumStorePurchases', 'NumWebVisitsMonth', 'AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5', 'AcceptedCmp1', 'AcceptedCmp2', 'Complain', 'Z_CostContact', 'Z_Revenue', 'Response', 'Top_Product']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c43e71ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Dashboard Snapshot:\n",
      "   Dt_customer Predicted Product  Customer Segment\n",
      "0          961          MntWines                 2\n",
      "1          229   MntMeatProducts                 2\n",
      "2         1093          MntWines                 0\n",
      "3          427          MntWines                 3\n",
      "4         1650   MntFishProducts                 2\n",
      "5          543          MntWines                 3\n",
      "6         1801          MntWines                 1\n",
      "7         1708          MntWines                 2\n",
      "8          994          MntWines                 2\n",
      "9          976          MntWines                 1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Select features and drop rows with missing values\n",
    "features = ['Income', 'Recency', 'MntWines', 'MntMeatProducts']\n",
    "df_cluster = df.dropna(subset=features).copy()\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "scaled = scaler.fit_transform(df_cluster[features])\n",
    "\n",
    "# Apply KMeans\n",
    "kmeans = KMeans(n_clusters=4, random_state=42)\n",
    "df_cluster['Customer Segment'] = kmeans.fit_predict(scaled)\n",
    "\n",
    "# Sample 10 for dashboard\n",
    "dashboard = df_cluster[['Top_Product', 'Customer Segment']].sample(10, random_state=42)\n",
    "dashboard.reset_index(inplace=True)\n",
    "dashboard.rename(columns={'index': 'Dt_customer', 'Top_Product': 'Predicted Product'}, inplace=True)\n",
    "\n",
    "# Show dashboard\n",
    "print(\"📊 Dashboard Snapshot:\")\n",
    "print(dashboard)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
