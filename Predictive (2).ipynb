{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6be95a56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Year_Birth</th>\n",
       "      <th>Education</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Income</th>\n",
       "      <th>Kidhome</th>\n",
       "      <th>Teenhome</th>\n",
       "      <th>Dt_Customer</th>\n",
       "      <th>Recency</th>\n",
       "      <th>MntWines</th>\n",
       "      <th>...</th>\n",
       "      <th>NumWebVisitsMonth</th>\n",
       "      <th>AcceptedCmp3</th>\n",
       "      <th>AcceptedCmp4</th>\n",
       "      <th>AcceptedCmp5</th>\n",
       "      <th>AcceptedCmp1</th>\n",
       "      <th>AcceptedCmp2</th>\n",
       "      <th>Complain</th>\n",
       "      <th>Z_CostContact</th>\n",
       "      <th>Z_Revenue</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5524</td>\n",
       "      <td>1957</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Single</td>\n",
       "      <td>58138.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>04-09-2012</td>\n",
       "      <td>58</td>\n",
       "      <td>635</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2174</td>\n",
       "      <td>1954</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Single</td>\n",
       "      <td>46344.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>08-03-2014</td>\n",
       "      <td>38</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4141</td>\n",
       "      <td>1965</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Together</td>\n",
       "      <td>71613.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21-08-2013</td>\n",
       "      <td>26</td>\n",
       "      <td>426</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6182</td>\n",
       "      <td>1984</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Together</td>\n",
       "      <td>26646.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10-02-2014</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5324</td>\n",
       "      <td>1981</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Married</td>\n",
       "      <td>58293.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19-01-2014</td>\n",
       "      <td>94</td>\n",
       "      <td>173</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID  Year_Birth   Education Marital_Status   Income  Kidhome  Teenhome  \\\n",
       "0  5524        1957  Graduation         Single  58138.0        0         0   \n",
       "1  2174        1954  Graduation         Single  46344.0        1         1   \n",
       "2  4141        1965  Graduation       Together  71613.0        0         0   \n",
       "3  6182        1984  Graduation       Together  26646.0        1         0   \n",
       "4  5324        1981         PhD        Married  58293.0        1         0   \n",
       "\n",
       "  Dt_Customer  Recency  MntWines  ...  NumWebVisitsMonth  AcceptedCmp3  \\\n",
       "0  04-09-2012       58       635  ...                  7             0   \n",
       "1  08-03-2014       38        11  ...                  5             0   \n",
       "2  21-08-2013       26       426  ...                  4             0   \n",
       "3  10-02-2014       26        11  ...                  6             0   \n",
       "4  19-01-2014       94       173  ...                  5             0   \n",
       "\n",
       "   AcceptedCmp4  AcceptedCmp5  AcceptedCmp1  AcceptedCmp2  Complain  \\\n",
       "0             0             0             0             0         0   \n",
       "1             0             0             0             0         0   \n",
       "2             0             0             0             0         0   \n",
       "3             0             0             0             0         0   \n",
       "4             0             0             0             0         0   \n",
       "\n",
       "   Z_CostContact  Z_Revenue  Response  \n",
       "0              3         11         1  \n",
       "1              3         11         0  \n",
       "2              3         11         0  \n",
       "3              3         11         0  \n",
       "4              3         11         0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('customer_segmentation.csv')  # Replace with actual filename\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c8f59c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"customer_segmentation.csv\")  # replace with your file path\n",
    "\n",
    "# Drop useless columns\n",
    "df.drop(['ID', 'Dt_Customer', 'Z_CostContact', 'Z_Revenue'], axis=1, inplace=True)\n",
    "\n",
    "# Drop rows with missing income\n",
    "df.dropna(subset=['Income'], inplace=True)\n",
    "\n",
    "# OPTIONAL: Impute or drop other missing values\n",
    "df.dropna(inplace=True)  # safest start\n",
    "\n",
    "# Create a new target variable: Most purchased product\n",
    "product_columns = ['MntWines', 'MntFruits', 'MntMeatProducts',\n",
    "                   'MntFishProducts', 'MntSweetProducts', 'MntGoldProds']\n",
    "df['TargetProduct'] = df[product_columns].idxmax(axis=1)\n",
    "\n",
    "# Encode categorical features\n",
    "df = pd.get_dummies(df, columns=['Education', 'Marital_Status'], drop_first=True)\n",
    "\n",
    "# Encode target\n",
    "le = LabelEncoder()\n",
    "df['TargetProduct'] = le.fit_transform(df['TargetProduct'])\n",
    "\n",
    "# Features and label\n",
    "X = df.drop(['TargetProduct'], axis=1)\n",
    "y = df['TargetProduct']\n",
    "\n",
    "# Standardize numeric features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2,\n",
    "                                                    random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "92722cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Training Logistic Regression...\n",
      "\n",
      "📊 Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.25      0.30        12\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       0.62      0.64      0.63        33\n",
      "           3       0.84      0.69      0.76        88\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       0.90      0.97      0.94       305\n",
      "\n",
      "    accuracy                           0.86       444\n",
      "   macro avg       0.46      0.43      0.44       444\n",
      "weighted avg       0.84      0.86      0.85       444\n",
      "\n",
      "\n",
      "🔍 Training k-NN...\n",
      "\n",
      "📊 k-NN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.25      0.25        12\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       0.36      0.42      0.39        33\n",
      "           3       0.52      0.38      0.43        88\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       0.82      0.88      0.85       305\n",
      "\n",
      "    accuracy                           0.72       444\n",
      "   macro avg       0.32      0.32      0.32       444\n",
      "weighted avg       0.70      0.72      0.71       444\n",
      "\n",
      "\n",
      "🔍 Training Decision Tree...\n",
      "\n",
      "📊 Decision Tree Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67        12\n",
      "           1       0.50      0.33      0.40         3\n",
      "           2       0.78      0.85      0.81        33\n",
      "           3       0.88      0.80      0.83        88\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       0.94      0.96      0.95       305\n",
      "\n",
      "    accuracy                           0.90       444\n",
      "   macro avg       0.63      0.60      0.61       444\n",
      "weighted avg       0.90      0.90      0.90       444\n",
      "\n",
      "\n",
      "🔍 Training Random Forest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.33      0.44        12\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       0.66      0.76      0.70        33\n",
      "           3       0.85      0.64      0.73        88\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       0.90      0.98      0.94       305\n",
      "\n",
      "    accuracy                           0.86       444\n",
      "   macro avg       0.51      0.45      0.47       444\n",
      "weighted avg       0.85      0.86      0.85       444\n",
      "\n",
      "\n",
      "🔍 Training XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:35:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 XGBoost Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.58      0.64        12\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       0.78      0.97      0.86        33\n",
      "           3       0.89      0.90      0.89        88\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       0.98      0.97      0.97       305\n",
      "\n",
      "    accuracy                           0.93       444\n",
      "   macro avg       0.56      0.57      0.56       444\n",
      "weighted avg       0.92      0.93      0.93       444\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# Define models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'k-NN': KNeighborsClassifier(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "}\n",
    "\n",
    "# Train and evaluate\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n🔍 Training {name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"\\n📊 {name} Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "06d4d59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Classification Report for Logistic Regression:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.25      0.30        12\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       0.62      0.64      0.63        33\n",
      "           3       0.84      0.69      0.76        88\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       0.90      0.97      0.94       305\n",
      "\n",
      "    accuracy                           0.86       444\n",
      "   macro avg       0.46      0.43      0.44       444\n",
      "weighted avg       0.84      0.86      0.85       444\n",
      "\n",
      "\n",
      "🔍 Classification Report for k-NN:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.25      0.25        12\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       0.36      0.42      0.39        33\n",
      "           3       0.52      0.38      0.43        88\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       0.82      0.88      0.85       305\n",
      "\n",
      "    accuracy                           0.72       444\n",
      "   macro avg       0.32      0.32      0.32       444\n",
      "weighted avg       0.70      0.72      0.71       444\n",
      "\n",
      "\n",
      "🔍 Classification Report for Decision Tree:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.75      0.69        12\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       0.78      0.85      0.81        33\n",
      "           3       0.90      0.80      0.84        88\n",
      "           4       0.33      0.33      0.33         3\n",
      "           5       0.94      0.97      0.95       305\n",
      "\n",
      "    accuracy                           0.91       444\n",
      "   macro avg       0.60      0.62      0.61       444\n",
      "weighted avg       0.90      0.91      0.90       444\n",
      "\n",
      "\n",
      "🔍 Classification Report for Random Forest:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.42      0.53        12\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       0.68      0.79      0.73        33\n",
      "           3       0.81      0.59      0.68        88\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       0.89      0.97      0.93       305\n",
      "\n",
      "    accuracy                           0.86       444\n",
      "   macro avg       0.52      0.46      0.48       444\n",
      "weighted avg       0.84      0.86      0.84       444\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:35:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Classification Report for XGBoost:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.58      0.64        12\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       0.78      0.97      0.86        33\n",
      "           3       0.89      0.90      0.89        88\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       0.98      0.97      0.97       305\n",
      "\n",
      "    accuracy                           0.93       444\n",
      "   macro avg       0.56      0.57      0.56       444\n",
      "weighted avg       0.92      0.93      0.93       444\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>AUC-ROC (Macro)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.8604</td>\n",
       "      <td>0.4552</td>\n",
       "      <td>0.4256</td>\n",
       "      <td>0.4369</td>\n",
       "      <td>0.9524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>k-NN</td>\n",
       "      <td>0.7185</td>\n",
       "      <td>0.3241</td>\n",
       "      <td>0.3219</td>\n",
       "      <td>0.3205</td>\n",
       "      <td>0.7060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.9077</td>\n",
       "      <td>0.5990</td>\n",
       "      <td>0.6157</td>\n",
       "      <td>0.6059</td>\n",
       "      <td>0.7922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.8559</td>\n",
       "      <td>0.5163</td>\n",
       "      <td>0.4615</td>\n",
       "      <td>0.4785</td>\n",
       "      <td>0.9837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.9324</td>\n",
       "      <td>0.5575</td>\n",
       "      <td>0.5702</td>\n",
       "      <td>0.5613</td>\n",
       "      <td>0.9927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Precision  Recall  F1-Score  AUC-ROC (Macro)\n",
       "0  Logistic Regression    0.8604     0.4552  0.4256    0.4369           0.9524\n",
       "1                 k-NN    0.7185     0.3241  0.3219    0.3205           0.7060\n",
       "2        Decision Tree    0.9077     0.5990  0.6157    0.6059           0.7922\n",
       "3        Random Forest    0.8559     0.5163  0.4615    0.4785           0.9837\n",
       "4              XGBoost    0.9324     0.5575  0.5702    0.5613           0.9927"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Label encode target if it's not numeric\n",
    "if y_train.dtype == 'object':\n",
    "    le = LabelEncoder()\n",
    "    y_train_enc = le.fit_transform(y_train)\n",
    "    y_test_enc = le.transform(y_test)\n",
    "else:\n",
    "    y_train_enc = y_train\n",
    "    y_test_enc = y_test\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"k-NN\": KNeighborsClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "}\n",
    "\n",
    "# Store evaluation metrics\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train_enc)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test_enc, y_pred)\n",
    "    precision = precision_score(y_test_enc, y_pred, average='macro', zero_division=0)\n",
    "    recall = recall_score(y_test_enc, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test_enc, y_pred, average='macro')\n",
    "    \n",
    "    # AUC-ROC for multiclass\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_proba = model.predict_proba(X_test)\n",
    "        auc = roc_auc_score(y_test_enc, y_proba, multi_class='ovr', average='macro')\n",
    "    else:\n",
    "        auc = None\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": round(accuracy, 4),\n",
    "        \"Precision\": round(precision, 4),\n",
    "        \"Recall\": round(recall, 4),\n",
    "        \"F1-Score\": round(f1, 4),\n",
    "        \"AUC-ROC (Macro)\": round(auc, 4) if auc else \"N/A\"\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n🔍 Classification Report for {name}:\\n\")\n",
    "    print(classification_report(y_test_enc, y_pred, zero_division=0))\n",
    "\n",
    "# Display results in DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "display(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70feff7",
   "metadata": {},
   "source": [
    "### HYPER PARAMETER TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c3fc4e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grids = {\n",
    "    \"Logistic Regression\": {\n",
    "        \"C\": [0.01, 0.1, 1, 10],\n",
    "        \"solver\": [\"liblinear\", \"lbfgs\"]\n",
    "    },\n",
    "    \"k-NN\": {\n",
    "        \"n_neighbors\": [3, 5, 7],\n",
    "        \"weights\": [\"uniform\", \"distance\"]\n",
    "    },\n",
    "    \"Decision Tree\": {\n",
    "        \"max_depth\": [5, 10, 15],\n",
    "        \"min_samples_split\": [2, 5, 10]\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        \"n_estimators\": [100, 200],\n",
    "        \"max_depth\": [None, 10, 20],\n",
    "        \"min_samples_split\": [2, 5]\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        \"n_estimators\": [100, 200],\n",
    "        \"max_depth\": [3, 5, 7],\n",
    "        \"learning_rate\": [0.05, 0.1]\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2e6d2535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Tuning Logistic Regression...\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "✅ Best Params: {'C': 10, 'solver': 'lbfgs'}\n",
      "\n",
      "🔍 Tuning k-NN...\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "✅ Best Params: {'n_neighbors': 7, 'weights': 'distance'}\n",
      "\n",
      "🔍 Tuning Decision Tree...\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "✅ Best Params: {'max_depth': 15, 'min_samples_split': 2}\n",
      "\n",
      "🔍 Tuning Random Forest...\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "✅ Best Params: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "\n",
      "🔍 Tuning XGBoost...\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:36:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best Params: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"k-NN\": KNeighborsClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "}\n",
    "\n",
    "best_models = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n🔍 Tuning {name}...\")\n",
    "    grid = GridSearchCV(model, param_grids[name], cv=3, scoring='f1_macro', n_jobs=-1, verbose=1)\n",
    "    \n",
    "    if name == \"XGBoost\":\n",
    "        grid.fit(X_train, y_train_enc)\n",
    "    else:\n",
    "        grid.fit(X_train, y_train)\n",
    "\n",
    "    best_models[name] = grid.best_estimator_\n",
    "    print(\"✅ Best Params:\", grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1301e6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📄 Classification Report for Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.58      0.58        12\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       0.67      0.73      0.70        33\n",
      "           3       0.88      0.82      0.85        88\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       0.96      0.98      0.97       305\n",
      "\n",
      "    accuracy                           0.91       444\n",
      "   macro avg       0.51      0.52      0.52       444\n",
      "weighted avg       0.90      0.91      0.90       444\n",
      "\n",
      "\n",
      "📄 Classification Report for k-NN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.17      0.22        12\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       0.33      0.30      0.32        33\n",
      "           3       0.62      0.45      0.52        88\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       0.81      0.91      0.86       305\n",
      "\n",
      "    accuracy                           0.74       444\n",
      "   macro avg       0.35      0.31      0.32       444\n",
      "weighted avg       0.71      0.74      0.72       444\n",
      "\n",
      "\n",
      "📄 Classification Report for Decision Tree:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.75      0.69        12\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       0.74      0.85      0.79        33\n",
      "           3       0.83      0.77      0.80        88\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       0.94      0.95      0.95       305\n",
      "\n",
      "    accuracy                           0.89       444\n",
      "   macro avg       0.53      0.55      0.54       444\n",
      "weighted avg       0.89      0.89      0.89       444\n",
      "\n",
      "\n",
      "📄 Classification Report for Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.42      0.50        12\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       0.64      0.70      0.67        33\n",
      "           3       0.85      0.66      0.74        88\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       0.90      0.98      0.94       305\n",
      "\n",
      "    accuracy                           0.86       444\n",
      "   macro avg       0.50      0.46      0.47       444\n",
      "weighted avg       0.85      0.86      0.85       444\n",
      "\n",
      "\n",
      "📄 Classification Report for XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.50      0.60        12\n",
      "           1       1.00      0.33      0.50         3\n",
      "           2       0.78      0.94      0.85        33\n",
      "           3       0.91      0.88      0.89        88\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       0.97      0.98      0.97       305\n",
      "\n",
      "    accuracy                           0.93       444\n",
      "   macro avg       0.73      0.60      0.64       444\n",
      "weighted avg       0.93      0.93      0.93       444\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>AUC-ROC (Macro)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.907658</td>\n",
       "      <td>0.514419</td>\n",
       "      <td>0.518732</td>\n",
       "      <td>0.516153</td>\n",
       "      <td>0.976221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>k-NN</td>\n",
       "      <td>0.743243</td>\n",
       "      <td>0.349153</td>\n",
       "      <td>0.305953</td>\n",
       "      <td>0.320318</td>\n",
       "      <td>0.761354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.525629</td>\n",
       "      <td>0.554218</td>\n",
       "      <td>0.538412</td>\n",
       "      <td>0.760270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.502403</td>\n",
       "      <td>0.458296</td>\n",
       "      <td>0.474315</td>\n",
       "      <td>0.984468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.932432</td>\n",
       "      <td>0.733087</td>\n",
       "      <td>0.604676</td>\n",
       "      <td>0.635572</td>\n",
       "      <td>0.992701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Precision    Recall  F1-Score  \\\n",
       "0  Logistic Regression  0.907658   0.514419  0.518732  0.516153   \n",
       "1                 k-NN  0.743243   0.349153  0.305953  0.320318   \n",
       "2        Decision Tree  0.891892   0.525629  0.554218  0.538412   \n",
       "3        Random Forest  0.864865   0.502403  0.458296  0.474315   \n",
       "4              XGBoost  0.932432   0.733087  0.604676  0.635572   \n",
       "\n",
       "   AUC-ROC (Macro)  \n",
       "0         0.976221  \n",
       "1         0.761354  \n",
       "2         0.760270  \n",
       "3         0.984468  \n",
       "4         0.992701  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "report_data = []\n",
    "\n",
    "for name, model in best_models.items():\n",
    "    print(f\"\\n📄 Classification Report for {name}:\")\n",
    "\n",
    "    if name == \"XGBoost\":\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_proba = model.predict_proba(X_test)\n",
    "        auc = roc_auc_score(y_test_enc, y_proba, multi_class='ovr')\n",
    "    else:\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_proba = model.predict_proba(X_test)\n",
    "        auc = roc_auc_score(y_test, y_proba, multi_class='ovr')\n",
    "\n",
    "    print(classification_report(y_test if name != \"XGBoost\" else y_test_enc, y_pred))\n",
    "\n",
    "    report_data.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"Precision\": precision_score(y_test, y_pred, average='macro'),\n",
    "        \"Recall\": recall_score(y_test, y_pred, average='macro'),\n",
    "        \"F1-Score\": f1_score(y_test, y_pred, average='macro'),\n",
    "        \"AUC-ROC (Macro)\": auc\n",
    "    })\n",
    "\n",
    "# Display results\n",
    "df_report = pd.DataFrame(report_data)\n",
    "display(df_report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "10bd1bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Classification Report for Decision Tree:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.75      0.69        12\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       0.74      0.85      0.79        33\n",
      "           3       0.83      0.77      0.80        88\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       0.94      0.95      0.95       305\n",
      "\n",
      "    accuracy                           0.89       444\n",
      "   macro avg       0.53      0.55      0.54       444\n",
      "weighted avg       0.89      0.89      0.89       444\n",
      "\n",
      "🧠 AUC-ROC (Macro) for Decision Tree: 0.7603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Make predictions using the best Decision Tree model\n",
    "y_pred_dt = best_models['Decision Tree'].predict(X_test)\n",
    "y_proba_dt = best_models['Decision Tree'].predict_proba(X_test)\n",
    "\n",
    "# If it's a multi-class task, use 'macro' average\n",
    "auc_roc_dt = roc_auc_score(y_test, y_proba_dt, multi_class='ovr', average='macro')\n",
    "\n",
    "# Classification Report\n",
    "print(\"📊 Classification Report for Decision Tree:\")\n",
    "print(classification_report(y_test, y_pred_dt))\n",
    "\n",
    "# AUC-ROC\n",
    "print(f\"🧠 AUC-ROC (Macro) for Decision Tree: {auc_roc_dt:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "aac15b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Classification Report for k-NN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.17      0.22        12\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       0.33      0.30      0.32        33\n",
      "           3       0.62      0.45      0.52        88\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       0.81      0.91      0.86       305\n",
      "\n",
      "    accuracy                           0.74       444\n",
      "   macro avg       0.35      0.31      0.32       444\n",
      "weighted avg       0.71      0.74      0.72       444\n",
      "\n",
      "🧠 AUC-ROC (Macro) for k-NN: 0.7614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Make predictions using the best k-NN model\n",
    "y_pred_knn = best_models['k-NN'].predict(X_test)\n",
    "y_proba_knn = best_models['k-NN'].predict_proba(X_test)\n",
    "\n",
    "# Calculate AUC-ROC Score (macro)\n",
    "auc_roc_knn = roc_auc_score(y_test, y_proba_knn, multi_class='ovr', average='macro')\n",
    "\n",
    "# Print Classification Report\n",
    "print(\"📊 Classification Report for k-NN:\")\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "# Print AUC-ROC Score\n",
    "print(f\"🧠 AUC-ROC (Macro) for k-NN: {auc_roc_knn:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fb59da56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable                 Type                      Data/Info\n",
      "------------------------------------------------------------\n",
      "DecisionTreeClassifier   ABCMeta                   <class 'sklearn.tree._cla<...>.DecisionTreeClassifier'>\n",
      "GridSearchCV             ABCMeta                   <class 'sklearn.model_sel<...>on._search.GridSearchCV'>\n",
      "KNeighborsClassifier     ABCMeta                   <class 'sklearn.neighbors<...>on.KNeighborsClassifier'>\n",
      "LabelEncoder             type                      <class 'sklearn.preproces<...>ing._label.LabelEncoder'>\n",
      "LogisticRegression       type                      <class 'sklearn.linear_mo<...>stic.LogisticRegression'>\n",
      "RandomForestClassifier   ABCMeta                   <class 'sklearn.ensemble.<...>.RandomForestClassifier'>\n",
      "StandardScaler           type                      <class 'sklearn.preproces<...>ng._data.StandardScaler'>\n",
      "X                        DataFrame                       Year_Birth   Income<...>n[2216 rows x 34 columns]\n",
      "XGBClassifier            type                      <class 'xgboost.sklearn.XGBClassifier'>\n",
      "X_scaled                 ndarray                   2216x34: 75344 elems, type `float64`, 602752 bytes (588.625 kb)\n",
      "X_test                   ndarray                   444x34: 15096 elems, type `float64`, 120768 bytes (117.9375 kb)\n",
      "X_test_scaled            ndarray                   444x27: 11988 elems, type `float64`, 95904 bytes\n",
      "X_train                  ndarray                   1772x34: 60248 elems, type `float64`, 481984 bytes (470.6875 kb)\n",
      "X_train_scaled           ndarray                   1772x27: 47844 elems, type `float64`, 382752 bytes (373.78125 kb)\n",
      "accuracy                 float                     0.9324324324324325\n",
      "accuracy_score           function                  <function accuracy_score at 0x000001AAC0842980>\n",
      "auc                      float                     0.9927011754280429\n",
      "auc_roc_dt               float                     0.7602701965990146\n",
      "auc_roc_knn              float                     0.7613536159759491\n",
      "best_model               XGBClassifier             XGBClassifier(base_score=<...>_parallel_tree=None, ...)\n",
      "best_models              dict                      n=5\n",
      "best_tuned_models        dict                      n=5\n",
      "booster                  Booster                   <xgboost.core.Booster obj<...>ct at 0x000001AAC0CA28B0>\n",
      "booster_feature_names    NoneType                  None\n",
      "classification_report    function                  <function classification_<...>rt at 0x000001AAC0843CE0>\n",
      "df                       DataFrame                       Year_Birth   Income<...>n[2216 rows x 35 columns]\n",
      "df_report                DataFrame                                  Model  A<...>8  \\n4         0.992701  \n",
      "dt_model                 DecisionTreeClassifier    DecisionTreeClassifier(random_state=42)\n",
      "f1                       float                     0.5612613464977426\n",
      "f1_score                 function                  <function f1_score at 0x000001AAC0843240>\n",
      "feature_importance_df    DataFrame                                     Featu<...>atus_Divorced    0.000000\n",
      "feature_names            list                      n=27\n",
      "grid                     GridSearchCV              GridSearchCV(cv=3,\\n     <...>ng='f1_macro', verbose=1)\n",
      "importances              ndarray                   27: 27 elems, type `float32`, 108 bytes\n",
      "knn_model                KNeighborsClassifier      KNeighborsClassifier()\n",
      "le                       LabelEncoder              LabelEncoder()\n",
      "model                    XGBClassifier             XGBClassifier(base_score=<...>_parallel_tree=None, ...)\n",
      "models                   dict                      n=5\n",
      "name                     str                       XGBoost\n",
      "np                       module                    <module 'numpy' from 'c:\\<...>ges\\\\numpy\\\\__init__.py'>\n",
      "param_grids              dict                      n=5\n",
      "pd                       module                    <module 'pandas' from 'c:<...>es\\\\pandas\\\\__init__.py'>\n",
      "plt                      module                    <module 'matplotlib.pyplo<...>\\\\matplotlib\\\\pyplot.py'>\n",
      "precision                float                     0.5575043240142047\n",
      "precision_score          function                  <function precision_score at 0x000001AAC0843920>\n",
      "product_columns          list                      n=6\n",
      "recall                   float                     0.5702082298393775\n",
      "recall_score             function                  <function recall_score at 0x000001AAC0843A60>\n",
      "report_data              list                      n=5\n",
      "results                  list                      n=5\n",
      "results_df               DataFrame                                  Model  A<...>  0.5613           0.9927\n",
      "rf_model                 RandomForestClassifier    RandomForestClassifier(random_state=42)\n",
      "roc_auc_score            function                  <function roc_auc_score at 0x000001AAC085F060>\n",
      "scaler                   StandardScaler            StandardScaler()\n",
      "train_test_split         function                  <function train_test_split at 0x000001AAC08D80E0>\n",
      "tuned_results            list                      n=5\n",
      "xgb_model                XGBClassifier             XGBClassifier(base_score=<...>_parallel_tree=None, ...)\n",
      "y                        Series                    0       5\\n1       5\\n2  <...>ength: 2216, dtype: int64\n",
      "y_encoded                ndarray                   2216: 2216 elems, type `int64`, 17728 bytes\n",
      "y_pred                   ndarray                   444: 444 elems, type `int64`, 3552 bytes\n",
      "y_pred_dt                ndarray                   444: 444 elems, type `int64`, 3552 bytes\n",
      "y_pred_knn               ndarray                   444: 444 elems, type `int64`, 3552 bytes\n",
      "y_pred_rf                ndarray                   444: 444 elems, type `int64`, 3552 bytes\n",
      "y_proba                  ndarray                   444x6: 2664 elems, type `float32`, 10656 bytes\n",
      "y_proba_dt               ndarray                   444x6: 2664 elems, type `float64`, 21312 bytes\n",
      "y_proba_knn              ndarray                   444x6: 2664 elems, type `float64`, 21312 bytes\n",
      "y_test                   Series                    1593    5\\n1134    5\\n222<...>Length: 444, dtype: int64\n",
      "y_test_enc               Series                    1593    5\\n1134    5\\n222<...>Length: 444, dtype: int64\n",
      "y_train                  Series                    767     5\\n1315    5\\n202<...>ength: 1772, dtype: int64\n",
      "y_train_enc              Series                    767     5\\n1315    5\\n202<...>ength: 1772, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "whos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c6001133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining columns after dropping product features and creating 'Children':\n",
      "Index(['Year_Birth', 'Income', 'Recency', 'NumDealsPurchases',\n",
      "       'NumWebPurchases', 'NumCatalogPurchases', 'NumStorePurchases',\n",
      "       'NumWebVisitsMonth', 'AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5',\n",
      "       'AcceptedCmp1', 'AcceptedCmp2', 'Complain', 'Response', 'TargetProduct',\n",
      "       'Education_Basic', 'Education_Graduation', 'Education_Master',\n",
      "       'Education_PhD', 'Marital_Status_Alone', 'Marital_Status_Divorced',\n",
      "       'Marital_Status_Married', 'Marital_Status_Single',\n",
      "       'Marital_Status_Together', 'Marital_Status_Widow',\n",
      "       'Marital_Status_YOLO', 'Children'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Drop product columns used as input features\n",
    "product_columns = [\n",
    "    'MntWines', 'MntFruits', 'MntMeatProducts',\n",
    "    'MntFishProducts', 'MntSweetProducts', 'MntGoldProds'\n",
    "]\n",
    "df = df.drop(columns=product_columns)\n",
    "\n",
    "# Optional: Create new 'Children' column and drop 'Kidhome' and 'Teenhome'\n",
    "df['Children'] = df['Kidhome'] + df['Teenhome']\n",
    "df = df.drop(columns=['Kidhome', 'Teenhome'])\n",
    "\n",
    "# Confirm dropped columns\n",
    "print(\"Remaining columns after dropping product features and creating 'Children':\")\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d4c72399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "59f97aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Assuming df is your cleaned DataFrame\n",
    "# Drop product features (already done), encode target\n",
    "X = df.drop(['TargetProduct'], axis=1)\n",
    "y = df['TargetProduct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cb850684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Encode target labels\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "88ed53d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9ffdcbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3767b0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Define models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'k-NN': KNeighborsClassifier(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "37d6af97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Training Logistic Regression\n",
      "\n",
      "📊 Classification Report for Logistic Regression:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.08      0.12        12\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       0.41      0.48      0.44        33\n",
      "           3       0.51      0.22      0.30        88\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       0.80      0.94      0.86       305\n",
      "\n",
      "    accuracy                           0.73       444\n",
      "   macro avg       0.32      0.29      0.29       444\n",
      "weighted avg       0.69      0.73      0.69       444\n",
      "\n",
      "\n",
      "🔍 Training k-NN\n",
      "\n",
      "📊 Classification Report for k-NN:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.08      0.09        12\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       0.30      0.36      0.33        33\n",
      "           3       0.44      0.31      0.36        88\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       0.79      0.85      0.82       305\n",
      "\n",
      "    accuracy                           0.67       444\n",
      "   macro avg       0.27      0.27      0.27       444\n",
      "weighted avg       0.65      0.67      0.66       444\n",
      "\n",
      "\n",
      "🔍 Training Decision Tree\n",
      "\n",
      "📊 Classification Report for Decision Tree:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.17      0.19        12\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       0.31      0.48      0.38        33\n",
      "           3       0.43      0.41      0.42        88\n",
      "           4       0.20      0.33      0.25         3\n",
      "           5       0.85      0.81      0.83       305\n",
      "\n",
      "    accuracy                           0.68       444\n",
      "   macro avg       0.34      0.37      0.35       444\n",
      "weighted avg       0.70      0.68      0.69       444\n",
      "\n",
      "\n",
      "🔍 Training Random Forest\n",
      "\n",
      "📊 Classification Report for Random Forest:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.17      0.24        12\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       0.44      0.52      0.47        33\n",
      "           3       0.51      0.38      0.43        88\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       0.84      0.92      0.88       305\n",
      "\n",
      "    accuracy                           0.75       444\n",
      "   macro avg       0.36      0.33      0.34       444\n",
      "weighted avg       0.72      0.75      0.73       444\n",
      "\n",
      "\n",
      "🔍 Training XGBoost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:36:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Classification Report for XGBoost:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.33      0.42        12\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       0.43      0.61      0.51        33\n",
      "           3       0.51      0.41      0.45        88\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       0.85      0.89      0.87       305\n",
      "\n",
      "    accuracy                           0.74       444\n",
      "   macro avg       0.39      0.37      0.37       444\n",
      "weighted avg       0.73      0.74      0.73       444\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>AUC-ROC (Macro)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.727477</td>\n",
       "      <td>0.320165</td>\n",
       "      <td>0.287512</td>\n",
       "      <td>0.288208</td>\n",
       "      <td>0.702014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>k-NN</td>\n",
       "      <td>0.671171</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.266615</td>\n",
       "      <td>0.265363</td>\n",
       "      <td>0.633765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.682432</td>\n",
       "      <td>0.336125</td>\n",
       "      <td>0.367842</td>\n",
       "      <td>0.345375</td>\n",
       "      <td>0.620705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.363733</td>\n",
       "      <td>0.329688</td>\n",
       "      <td>0.336169</td>\n",
       "      <td>0.763253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.743243</td>\n",
       "      <td>0.393718</td>\n",
       "      <td>0.372288</td>\n",
       "      <td>0.374498</td>\n",
       "      <td>0.740722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Precision    Recall  F1-Score  \\\n",
       "0  Logistic Regression  0.727477   0.320165  0.287512  0.288208   \n",
       "1                 k-NN  0.671171   0.269231  0.266615  0.265363   \n",
       "2        Decision Tree  0.682432   0.336125  0.367842  0.345375   \n",
       "3        Random Forest  0.750000   0.363733  0.329688  0.336169   \n",
       "4              XGBoost  0.743243   0.393718  0.372288  0.374498   \n",
       "\n",
       "   AUC-ROC (Macro)  \n",
       "0         0.702014  \n",
       "1         0.633765  \n",
       "2         0.620705  \n",
       "3         0.763253  \n",
       "4         0.740722  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# 7. Evaluate models\n",
    "report_data = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n🔍 Training {name}\")\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "\n",
    "    try:\n",
    "        auc = roc_auc_score(y_test, model.predict_proba(X_test_scaled), multi_class='ovo', average='macro')\n",
    "    except:\n",
    "        auc = np.nan\n",
    "\n",
    "    report_data.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'AUC-ROC (Macro)': auc\n",
    "    })\n",
    "\n",
    "    print(f\"\\n📊 Classification Report for {name}:\\n\")\n",
    "    print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "# Show summary\n",
    "import pandas as pd\n",
    "df_report = pd.DataFrame(report_data)\n",
    "df_report.reset_index(drop=True, inplace=True)\n",
    "df_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9c61ba86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Classification Report for Random Forest:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.17      0.27        12\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       0.42      0.48      0.45        33\n",
      "           3       0.55      0.40      0.46        88\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       0.84      0.93      0.89       305\n",
      "\n",
      "    accuracy                           0.76       444\n",
      "   macro avg       0.41      0.33      0.34       444\n",
      "weighted avg       0.74      0.76      0.74       444\n",
      "\n",
      "Accuracy: 0.7612612612612613\n",
      "Precision: 0.41255037714123066\n",
      "Recall: 0.33061144229177014\n",
      "F1 Score: 0.3438317292516861\n",
      "AUC ROC (Macro): 0.7073601561441539\n",
      "\n",
      "📊 Classification Report for Decision Tree:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.25      0.29        12\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       0.34      0.48      0.40        33\n",
      "           3       0.38      0.36      0.37        88\n",
      "           4       0.17      0.33      0.22         3\n",
      "           5       0.84      0.81      0.82       305\n",
      "\n",
      "    accuracy                           0.67       444\n",
      "   macro avg       0.34      0.37      0.35       444\n",
      "weighted avg       0.69      0.67      0.68       444\n",
      "\n",
      "Accuracy: 0.6711711711711712\n",
      "Precision: 0.3427477606393658\n",
      "Recall: 0.37306259314456036\n",
      "F1 Score: 0.350103529897448\n",
      "AUC ROC (Macro): 0.6238375558867362\n",
      "\n",
      "📊 Classification Report for k-NN:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.08      0.09        12\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       0.30      0.36      0.33        33\n",
      "           3       0.44      0.31      0.36        88\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       0.79      0.85      0.82       305\n",
      "\n",
      "    accuracy                           0.67       444\n",
      "   macro avg       0.27      0.27      0.27       444\n",
      "weighted avg       0.65      0.67      0.66       444\n",
      "\n",
      "Accuracy: 0.6711711711711712\n",
      "Precision: 0.2692306312608177\n",
      "Recall: 0.26661491968869017\n",
      "F1 Score: 0.2653632235382222\n",
      "AUC ROC (Macro): 0.6337654049185345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
    "\n",
    "# Random Forest\n",
    "print(\"📊 Classification Report for Random Forest:\\n\")\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_rf, average='macro'))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_rf, average='macro'))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_rf, average='macro'))\n",
    "print(\"AUC ROC (Macro):\", roc_auc_score(y_test, rf_model.predict_proba(X_test_scaled), multi_class='ovo', average='macro'))\n",
    "\n",
    "\n",
    "# Decision Tree\n",
    "print(\"\\n📊 Classification Report for Decision Tree:\\n\")\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train_scaled, y_train)\n",
    "y_pred_dt = dt_model.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred_dt))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_dt))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_dt, average='macro'))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_dt, average='macro'))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_dt, average='macro'))\n",
    "print(\"AUC ROC (Macro):\", roc_auc_score(y_test, dt_model.predict_proba(X_test_scaled), multi_class='ovo', average='macro'))\n",
    "\n",
    "\n",
    "# k-NN\n",
    "print(\"\\n📊 Classification Report for k-NN:\\n\")\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(X_train_scaled, y_train)\n",
    "y_pred_knn = knn_model.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_knn))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_knn, average='macro'))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_knn, average='macro'))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_knn, average='macro'))\n",
    "print(\"AUC ROC (Macro):\", roc_auc_score(y_test, knn_model.predict_proba(X_test_scaled), multi_class='ovo', average='macro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "43892826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Classification Report for Decision Tree:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.25      0.29        12\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       0.34      0.48      0.40        33\n",
      "           3       0.38      0.36      0.37        88\n",
      "           4       0.17      0.33      0.22         3\n",
      "           5       0.84      0.81      0.82       305\n",
      "\n",
      "    accuracy                           0.67       444\n",
      "   macro avg       0.34      0.37      0.35       444\n",
      "weighted avg       0.69      0.67      0.68       444\n",
      "\n",
      "Accuracy: 0.6711711711711712\n",
      "Precision: 0.3427477606393658\n",
      "Recall: 0.37306259314456036\n",
      "F1 Score: 0.350103529897448\n",
      "AUC ROC (Macro): 0.6238375558867362\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "print(\"\\n📊 Classification Report for Decision Tree:\\n\")\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train_scaled, y_train)\n",
    "y_pred_dt = dt_model.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred_dt))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_dt))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_dt, average='macro'))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_dt, average='macro'))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_dt, average='macro'))\n",
    "print(\"AUC ROC (Macro):\", roc_auc_score(y_test, dt_model.predict_proba(X_test_scaled), multi_class='ovo', average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "62886dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Classification Report for k-NN:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.08      0.09        12\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       0.30      0.36      0.33        33\n",
      "           3       0.44      0.31      0.36        88\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       0.79      0.85      0.82       305\n",
      "\n",
      "    accuracy                           0.67       444\n",
      "   macro avg       0.27      0.27      0.27       444\n",
      "weighted avg       0.65      0.67      0.66       444\n",
      "\n",
      "Accuracy: 0.6711711711711712\n",
      "Precision: 0.2692306312608177\n",
      "Recall: 0.26661491968869017\n",
      "F1 Score: 0.2653632235382222\n",
      "AUC ROC (Macro): 0.6337654049185345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# k-NN\n",
    "print(\"\\n📊 Classification Report for k-NN:\\n\")\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(X_train_scaled, y_train)\n",
    "y_pred_knn = knn_model.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_knn))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_knn, average='macro'))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_knn, average='macro'))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_knn, average='macro'))\n",
    "print(\"AUC ROC (Macro):\", roc_auc_score(y_test, knn_model.predict_proba(X_test_scaled), multi_class='ovo', average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc1bf29",
   "metadata": {},
   "source": [
    "### HYPERPARAMETER TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "df809fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Tuning Random Forest...\n",
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "\n",
      "✅ Best Parameters for Random Forest: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "\n",
      "📊 Classification Report for Tuned Random Forest:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.17      0.25        12\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       0.45      0.52      0.48        33\n",
      "           3       0.56      0.42      0.48        88\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       0.84      0.93      0.88       305\n",
      "\n",
      "    accuracy                           0.76       444\n",
      "   macro avg       0.39      0.34      0.35       444\n",
      "weighted avg       0.74      0.76      0.74       444\n",
      "\n",
      "Accuracy: 0.7635135135135135\n",
      "Precision: 0.39170606440343286\n",
      "Recall: 0.33835692995529065\n",
      "F1 Score: 0.34873133996148215\n",
      "AUC-ROC (Macro): 0.7057185804894449\n",
      "\n",
      "🔍 Tuning Decision Tree...\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "\n",
      "✅ Best Parameters for Decision Tree: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "\n",
      "📊 Classification Report for Tuned Decision Tree:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.17      0.18        12\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       0.38      0.52      0.44        33\n",
      "           3       0.42      0.35      0.38        88\n",
      "           4       0.20      0.33      0.25         3\n",
      "           5       0.83      0.84      0.83       305\n",
      "\n",
      "    accuracy                           0.69       444\n",
      "   macro avg       0.34      0.37      0.35       444\n",
      "weighted avg       0.69      0.69      0.69       444\n",
      "\n",
      "Accuracy: 0.6891891891891891\n",
      "Precision: 0.33788593153414\n",
      "Recall: 0.3672483026991224\n",
      "F1 Score: 0.3472941667386112\n",
      "AUC-ROC (Macro): 0.6571105302904854\n",
      "\n",
      "🔍 Tuning k-NN...\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Best Parameters for k-NN: {'metric': 'euclidean', 'n_neighbors': 7, 'weights': 'distance'}\n",
      "\n",
      "📊 Classification Report for Tuned k-NN:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.17      0.22        12\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       0.39      0.36      0.38        33\n",
      "           3       0.57      0.42      0.48        88\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       0.80      0.89      0.84       305\n",
      "\n",
      "    accuracy                           0.73       444\n",
      "   macro avg       0.35      0.31      0.32       444\n",
      "weighted avg       0.70      0.73      0.71       444\n",
      "\n",
      "Accuracy: 0.7274774774774775\n",
      "Precision: 0.34867012646059176\n",
      "Recall: 0.3070934757410167\n",
      "F1 Score: 0.32093380830593105\n",
      "AUC-ROC (Macro): 0.6820454812029887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Define parameter grids\n",
    "param_grids = {\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 5],\n",
    "        'min_samples_leaf': [1, 2]\n",
    "    },\n",
    "    'Decision Tree': {\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 5],\n",
    "        'min_samples_leaf': [1, 2]\n",
    "    },\n",
    "    'k-NN': {\n",
    "        'n_neighbors': [3, 5, 7],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'metric': ['euclidean', 'manhattan']\n",
    "    }\n",
    "}\n",
    "\n",
    "# Models dictionary\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'k-NN': KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "# Dictionary to store best models\n",
    "best_tuned_models = {}\n",
    "\n",
    "# Run GridSearchCV for each model\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n🔍 Tuning {name}...\")\n",
    "    grid = GridSearchCV(model, param_grids[name], cv=3, scoring='f1_macro', n_jobs=-1, verbose=1)\n",
    "    grid.fit(X_train_scaled, y_train)\n",
    "    best_model = grid.best_estimator_\n",
    "    best_tuned_models[name] = best_model\n",
    "\n",
    "    # Predict and evaluate\n",
    "    y_pred = best_model.predict(X_test_scaled)\n",
    "    print(f\"\\n✅ Best Parameters for {name}: {grid.best_params_}\")\n",
    "    print(f\"\\n📊 Classification Report for Tuned {name}:\\n\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    try:\n",
    "        auc = roc_auc_score(y_test, best_model.predict_proba(X_test_scaled), multi_class='ovo', average='macro')\n",
    "    except:\n",
    "        auc = \"N/A\"\n",
    "\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Precision:\", precision_score(y_test, y_pred, average='macro'))\n",
    "    print(\"Recall:\", recall_score(y_test, y_pred, average='macro'))\n",
    "    print(\"F1 Score:\", f1_score(y_test, y_pred, average='macro'))\n",
    "    print(\"AUC-ROC (Macro):\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3b07cb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the original feature names before scaling\n",
    "feature_names = X.columns\n",
    "\n",
    "# Then scale\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "672f5406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of feature_names: 27\n",
      "Length of XGBoost importances: 34\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of feature_names:\", len(feature_names))\n",
    "print(\"Length of XGBoost importances:\", len(xgb_model.feature_importances_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9e68d662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-define X and y properly\n",
    "X = df.drop(['TargetProduct'], axis=1)\n",
    "y = df['TargetProduct']\n",
    "\n",
    "# Capture correct feature names before scaling\n",
    "feature_names = X.columns.tolist()\n",
    "\n",
    "# Then scale\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "aacb155e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correctly define X and y\n",
    "X = df.drop('TargetProduct', axis=1)\n",
    "y = df['TargetProduct']\n",
    "\n",
    "# Save feature names before scaling\n",
    "feature_names = X.columns.tolist()\n",
    "\n",
    "# Now scale the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "99b51181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of feature_names: 27\n",
      "Shape of X_scaled: (2216, 27)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length of feature_names: {len(feature_names)}\")\n",
    "print(f\"Shape of X_scaled: {X_scaled.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b10f2690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Feature names: 27\n",
      "✅ Importances: 34\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NumDealsPurchases</td>\n",
       "      <td>0.325036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NumCatalogPurchases</td>\n",
       "      <td>0.112978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NumWebVisitsMonth</td>\n",
       "      <td>0.075806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AcceptedCmp5</td>\n",
       "      <td>0.065877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Marital_Status_Together</td>\n",
       "      <td>0.045439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Income</td>\n",
       "      <td>0.043905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AcceptedCmp3</td>\n",
       "      <td>0.037338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NumStorePurchases</td>\n",
       "      <td>0.032291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AcceptedCmp4</td>\n",
       "      <td>0.029363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Complain</td>\n",
       "      <td>0.028653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AcceptedCmp1</td>\n",
       "      <td>0.018432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Children</td>\n",
       "      <td>0.018371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Marital_Status_Alone</td>\n",
       "      <td>0.017466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AcceptedCmp2</td>\n",
       "      <td>0.014466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Marital_Status_Married</td>\n",
       "      <td>0.012887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Marital_Status_YOLO</td>\n",
       "      <td>0.012188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Education_Basic</td>\n",
       "      <td>0.012167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NumWebPurchases</td>\n",
       "      <td>0.012120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Year_Birth</td>\n",
       "      <td>0.011593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Marital_Status_Single</td>\n",
       "      <td>0.010889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Feature  Importance\n",
       "3         NumDealsPurchases    0.325036\n",
       "5       NumCatalogPurchases    0.112978\n",
       "7         NumWebVisitsMonth    0.075806\n",
       "10             AcceptedCmp5    0.065877\n",
       "23  Marital_Status_Together    0.045439\n",
       "1                    Income    0.043905\n",
       "8              AcceptedCmp3    0.037338\n",
       "6         NumStorePurchases    0.032291\n",
       "9              AcceptedCmp4    0.029363\n",
       "13                 Complain    0.028653\n",
       "11             AcceptedCmp1    0.018432\n",
       "26                 Children    0.018371\n",
       "19     Marital_Status_Alone    0.017466\n",
       "12             AcceptedCmp2    0.014466\n",
       "21   Marital_Status_Married    0.012887\n",
       "25      Marital_Status_YOLO    0.012188\n",
       "15          Education_Basic    0.012167\n",
       "4           NumWebPurchases    0.012120\n",
       "0                Year_Birth    0.011593\n",
       "22    Marital_Status_Single    0.010889"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. Manually assign feature names from the original DataFrame\n",
    "feature_names = X.columns.tolist()  # X is your unscaled DataFrame before StandardScaler\n",
    "importances = xgb_model.feature_importances_\n",
    "\n",
    "# 2. Sanity check lengths\n",
    "print(f\"✅ Feature names: {len(feature_names)}\")\n",
    "print(f\"✅ Importances: {len(importances)}\")\n",
    "\n",
    "# 3. Fix mismatch: If importances > features, trim importances\n",
    "if len(importances) > len(feature_names):\n",
    "    importances = importances[:len(feature_names)]\n",
    "elif len(importances) < len(feature_names):\n",
    "    feature_names = feature_names[:len(importances)]\n",
    "\n",
    "# 4. Create DataFrame\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# 5. Plot bar chart\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(feature_importance_df['Feature'][:20][::-1], feature_importance_df['Importance'][:20][::-1])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Top 20 Feature Importances from XGBoost')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Display top 20 features\n",
    "feature_importance_df.head(20)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
